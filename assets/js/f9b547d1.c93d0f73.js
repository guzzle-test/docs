(self.webpackChunkguzzle=self.webpackChunkguzzle||[]).push([[6037],{3905:function(e,t,a){"use strict";a.d(t,{Zo:function(){return u},kt:function(){return h}});var n=a(7294);function r(e,t,a){return t in e?Object.defineProperty(e,t,{value:a,enumerable:!0,configurable:!0,writable:!0}):e[t]=a,e}function o(e,t){var a=Object.keys(e);if(Object.getOwnPropertySymbols){var n=Object.getOwnPropertySymbols(e);t&&(n=n.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),a.push.apply(a,n)}return a}function i(e){for(var t=1;t<arguments.length;t++){var a=null!=arguments[t]?arguments[t]:{};t%2?o(Object(a),!0).forEach((function(t){r(e,t,a[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(a)):o(Object(a)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(a,t))}))}return e}function s(e,t){if(null==e)return{};var a,n,r=function(e,t){if(null==e)return{};var a,n,r={},o=Object.keys(e);for(n=0;n<o.length;n++)a=o[n],t.indexOf(a)>=0||(r[a]=e[a]);return r}(e,t);if(Object.getOwnPropertySymbols){var o=Object.getOwnPropertySymbols(e);for(n=0;n<o.length;n++)a=o[n],t.indexOf(a)>=0||Object.prototype.propertyIsEnumerable.call(e,a)&&(r[a]=e[a])}return r}var l=n.createContext({}),c=function(e){var t=n.useContext(l),a=t;return e&&(a="function"==typeof e?e(t):i(i({},t),e)),a},u=function(e){var t=c(e.components);return n.createElement(l.Provider,{value:t},e.children)},d={inlineCode:"code",wrapper:function(e){var t=e.children;return n.createElement(n.Fragment,{},t)}},p=n.forwardRef((function(e,t){var a=e.components,r=e.mdxType,o=e.originalType,l=e.parentName,u=s(e,["components","mdxType","originalType","parentName"]),p=c(a),h=r,m=p["".concat(l,".").concat(h)]||p[h]||d[h]||o;return a?n.createElement(m,i(i({ref:t},u),{},{components:a})):n.createElement(m,i({ref:t},u))}));function h(e,t){var a=arguments,r=t&&t.mdxType;if("string"==typeof e||r){var o=a.length,i=new Array(o);i[0]=p;var s={};for(var l in t)hasOwnProperty.call(t,l)&&(s[l]=t[l]);s.originalType=e,s.mdxType="string"==typeof e?e:r,i[1]=s;for(var c=2;c<o;c++)i[c]=a[c];return n.createElement.apply(null,i)}return n.createElement.apply(null,a)}p.displayName="MDXCreateElement"},7498:function(e,t,a){"use strict";a.r(t),a.d(t,{frontMatter:function(){return s},metadata:function(){return l},toc:function(){return c},default:function(){return d}});var n=a(2122),r=a(9756),o=(a(7294),a(3905)),i=["components"],s={},l={unversionedId:"How to guides/Ingest data/Working with Databases- HIVE",id:"How to guides/Ingest data/Working with Databases- HIVE",isDocsHomePage:!1,title:"Working with Databases- HIVE",description:"Only supported on Databricks compute",source:"@site/docs/How to guides/Ingest data/Working with Databases- HIVE.md",sourceDirName:"How to guides/Ingest data",slug:"/How to guides/Ingest data/Working with Databases- HIVE",permalink:"/docs/How to guides/Ingest data/Working with Databases- HIVE",editUrl:"https://github.com/ja-guzzle/docs/blob/master/docs/How to guides/Ingest data/Working with Databases- HIVE.md",version:"current",frontMatter:{},sidebar:"tutorialSidebar",previous:{title:"Working with Databases- Azure Synapse Analytics",permalink:"/docs/How to guides/Ingest data/Working with Databases- Azure Synapse Analytics"},next:{title:"Working with Databases- JDBC",permalink:"/docs/How to guides/Ingest data/Working with Databases- JDBC"}},c=[{value:"Apache Hive as a Source",id:"apache-hive-as-a-source",children:[]},{value:"Apache Hive as a Target or Reject",id:"apache-hive-as-a-target-or-reject",children:[]}],u={toc:c};function d(e){var t=e.components,s=(0,r.Z)(e,i);return(0,o.kt)("wrapper",(0,n.Z)({},u,s,{components:t,mdxType:"MDXLayout"}),(0,o.kt)("p",null,(0,o.kt)("strong",{parentName:"p"},"Only supported on Databricks compute")),(0,o.kt)("p",null,"Apache Hive is a data warehouse software project built on top of Apache Hadoop for providing data query and analysis. Hive gives an SQL-like interface to query data stored in various databases and file systems that integrate with Hadoop."),(0,o.kt)("p",null,"This article outlines how to use Hive as a source or target in Ingestion activity. Ingestion Active lets you leverage this native connector offered by Databricks and allows you to specify different configurations that are supported by this connector. "),(0,o.kt)("h2",{id:"apache-hive-as-a-source"},"Apache Hive as a Source"),(0,o.kt)("div",{className:"admonition admonition-note alert alert--secondary"},(0,o.kt)("div",{parentName:"div",className:"admonition-heading"},(0,o.kt)("h5",{parentName:"div"},(0,o.kt)("span",{parentName:"h5",className:"admonition-icon"},(0,o.kt)("svg",{parentName:"span",xmlns:"http://www.w3.org/2000/svg",width:"14",height:"16",viewBox:"0 0 14 16"},(0,o.kt)("path",{parentName:"svg",fillRule:"evenodd",d:"M6.3 5.69a.942.942 0 0 1-.28-.7c0-.28.09-.52.28-.7.19-.18.42-.28.7-.28.28 0 .52.09.7.28.18.19.28.42.28.7 0 .28-.09.52-.28.7a1 1 0 0 1-.7.3c-.28 0-.52-.11-.7-.3zM8 7.99c-.02-.25-.11-.48-.31-.69-.2-.19-.42-.3-.69-.31H6c-.27.02-.48.13-.69.31-.2.2-.3.44-.31.69h1v3c.02.27.11.5.31.69.2.2.42.31.69.31h1c.27 0 .48-.11.69-.31.2-.19.3-.42.31-.69H8V7.98v.01zM7 2.3c-3.14 0-5.7 2.54-5.7 5.68 0 3.14 2.56 5.7 5.7 5.7s5.7-2.55 5.7-5.7c0-3.15-2.56-5.69-5.7-5.69v.01zM7 .98c3.86 0 7 3.14 7 7s-3.14 7-7 7-7-3.12-7-7 3.14-7 7-7z"}))),": ")),(0,o.kt)("div",{parentName:"div",className:"admonition-content"},(0,o.kt)("p",{parentName:"div"},"In the Datastore section we can choose to read four Data either as a Table or through SQL (in the form of a query)."))),(0,o.kt)("table",null,(0,o.kt)("tr",null,(0,o.kt)("td",null,"Property "),(0,o.kt)("td",null,"Description"),(0,o.kt)("td",null,"Default Value"),(0,o.kt)("td",null,"Required")),(0,o.kt)("tr",null,(0,o.kt)("td",null,"Table + Filter"),(0,o.kt)("td",null,"Specify the table from where to read data. The table can contain schema and also database name. We can specify the Schema Name along with the Table Name. If it is not specified it is taken from the Datastore.",(0,o.kt)("p",null,"Also when the Table option is selected, you can also specify the Filter. The filter can be used to select only a part of the table. We may basically enter a condition and only the part of the table that satisfies the condition will be seen in the Target Section.")),(0,o.kt)("td",null,"None"),(0,o.kt)("td",null,"Yes.")),(0,o.kt)("tr",null,(0,o.kt)("td",null,"SQL"),(0,o.kt)("td",null,"Specify the SQL query which will be run as-is on the source"),(0,o.kt)("td",null),(0,o.kt)("td",null))),(0,o.kt)("h2",{id:"apache-hive-as-a-target-or-reject"},"Apache Hive as a Target or Reject"),(0,o.kt)("table",null,(0,o.kt)("tr",null,(0,o.kt)("td",null,"Property "),(0,o.kt)("td",null,"Description"),(0,o.kt)("td",null,"Default Value"),(0,o.kt)("td",null,"Required")),(0,o.kt)("tr",null,(0,o.kt)("td",null,"Table"),(0,o.kt)("td",null,"This is used to specify the Target Table we would like to create based on our Source."),(0,o.kt)("td",null,"None"),(0,o.kt)("td",null,"Yes")),(0,o.kt)("tr",null,(0,o.kt)("td",null,"Operation"),(0,o.kt)("td",null,"Provides two options that determines whether the content of source or reject data is expected to be -",(0,o.kt)("p",null,"append: To append the existing data in the Hive Table.\noverwrite:This will do an overwrite of data for a subset of partitions that are present in the source. The Partition columns are detected based on the source.")),(0,o.kt)("td",null,"append"),(0,o.kt)("td",null,"Yes")),(0,o.kt)("tr",null,(0,o.kt)("td",null,"Auto create table"),(0,o.kt)("td",null,"Guzzle provides the Auto Create Table feature in the Target Section. When selected it will automatically create a Target Table for us with the name as specified in the Table section above. In the schema section we have the Partition  indicator. This indicator is used when guzzle auto creates a table for Hive to decide the partition column. The order of partition columns will be according to how it appears in the Schema Section.",(0,o.kt)("p",null,"This can be seen in the figure below:")),(0,o.kt)("td",null,"True"),(0,o.kt)("td",null,"Yes"))),(0,o.kt)("p",null,(0,o.kt)("img",{alt:"image alt text",src:a(8437).Z})),(0,o.kt)("div",{className:"admonition admonition-note alert alert--secondary"},(0,o.kt)("div",{parentName:"div",className:"admonition-heading"},(0,o.kt)("h5",{parentName:"div"},(0,o.kt)("span",{parentName:"h5",className:"admonition-icon"},(0,o.kt)("svg",{parentName:"span",xmlns:"http://www.w3.org/2000/svg",width:"14",height:"16",viewBox:"0 0 14 16"},(0,o.kt)("path",{parentName:"svg",fillRule:"evenodd",d:"M6.3 5.69a.942.942 0 0 1-.28-.7c0-.28.09-.52.28-.7.19-.18.42-.28.7-.28.28 0 .52.09.7.28.18.19.28.42.28.7 0 .28-.09.52-.28.7a1 1 0 0 1-.7.3c-.28 0-.52-.11-.7-.3zM8 7.99c-.02-.25-.11-.48-.31-.69-.2-.19-.42-.3-.69-.31H6c-.27.02-.48.13-.69.31-.2.2-.3.44-.31.69h1v3c.02.27.11.5.31.69.2.2.42.31.69.31h1c.27 0 .48-.11.69-.31.2-.19.3-.42.31-.69H8V7.98v.01zM7 2.3c-3.14 0-5.7 2.54-5.7 5.68 0 3.14 2.56 5.7 5.7 5.7s5.7-2.55 5.7-5.7c0-3.15-2.56-5.69-5.7-5.69v.01zM7 .98c3.86 0 7 3.14 7 7s-3.14 7-7 7-7-3.12-7-7 3.14-7 7-7z"}))),"note")),(0,o.kt)("div",{parentName:"div",className:"admonition-content"},(0,o.kt)("p",{parentName:"div"},"When Guzzle creates a Table using the Auto Create Table option it will use the Partition Column Setting to determine the Partition Columns to use. The sequence will be as per the order specified."))))}d.isMDXComponent=!0},8437:function(e,t,a){"use strict";t.Z=a.p+"assets/images/hive-e26ecb1be010f31fafc6ce680674e0cd.png"}}]);